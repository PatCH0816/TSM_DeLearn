{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "worse-cloud",
   "metadata": {},
   "source": [
    "# Exercise 1 - Word polarity detection with word embedding\n",
    "The objective is to build a system that takes as input a word and outputs a probability that the\n",
    "word has a positive or negative connotation (polarity). As illustrated in Figure 1, the system is\n",
    "composed of two parts in which the word embedding part will leverage on pre-trained vectors\n",
    "such as the one obtained with word2vec or GloVe. If you are not familiar with word embeddings,\n",
    "we recommend you to watch the class material including videos and pdf posted on Moodle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-hopkins",
   "metadata": {},
   "source": [
    "a) Read lexicons. Download lists of positive and negative words from the Opinion Lexicon\n",
    "available from https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html. A zip\n",
    "is also provided on Moodle. Listing 1 provides an example of function to read the lexicons.\n",
    "You may want to complete the code to remove lines that start with ;, that end with +\n",
    "and to remove empty lines. You should get 2005 positive words and 4783 negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "statistical-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vocabulary_from_file (filename ):\n",
    "  with open(filename , 'r', encoding =\"ISO−8859−1\") as f:\n",
    "    content = f. readlines () # content is a list of lines\n",
    "    content = [x.strip () for x in content] # removing newline chars\n",
    "\n",
    "    # Remove elements containing ';' and '+'\n",
    "    content = [x for x in content if ';' not in x and len(x) > 0]\n",
    "    content = [x for x in content if '+' not in x and len(x) > 0]\n",
    "\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "consecutive-thompson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "OPINION LEXICON - ENGLISH\n",
      "==================================================\n",
      "Loaded negative words: 4783 words\n",
      "Loaded positive words: 2005 words\n"
     ]
    }
   ],
   "source": [
    "# LOAD OPINION LEXICON\n",
    "home_dir = 'opinion-lexicon-English/'\n",
    "neg_file = home_dir + 'negative-words.txt'\n",
    "pos_file = home_dir + 'positive-words.txt'\n",
    "\n",
    "vocab_neg = read_vocabulary_from_file(neg_file)\n",
    "vocab_pos = read_vocabulary_from_file(pos_file)\n",
    "print(\"=\"*50)\n",
    "print(\"OPINION LEXICON - ENGLISH\")\n",
    "print(\"=\"*50)\n",
    "print(\"Loaded negative words: {} words\".format(len(vocab_neg)))\n",
    "print(\"Loaded positive words: {} words\".format(len(vocab_pos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-yesterday",
   "metadata": {},
   "source": [
    "b) Convert words into vectors. You can here go for two options : either by querying\n",
    "an online API that returns you the vectors for a given word, or download a pre-trained\n",
    "word-vector dictionary (word2vec, GloVe, etc.). The code provided in Listing 2 shows you\n",
    "how to realise this using a GloVe embedding – zip also provided on Moodle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "found-genre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.6506757736206055, 12.520734786987305, -3.6179394721984863, 5.632171630859375, -3.351313352584839, -2.549443244934082, -2.328282117843628, 1.6070698499679565, -2.63830304145813, -1.2330397367477417, -3.712287425994873, 4.76062536239624, 1.0341637134552002, 2.15838885307312, -3.3286218643188477, -4.111255168914795, 1.6341111660003662, -1.8190534114837646, 3.094416379928589, 1.0175750255584717, -0.6583362817764282, 0.2975451350212097, -6.7455902099609375, -0.6072280406951904, -0.4232602119445801, -3.6135027408599854, 2.020463705062866, 8.311285972595215, 0.9904295206069946, 8.244004249572754, -1.4143904447555542, -6.177243232727051, -2.0402798652648926, 1.218432068824768, -0.2812301516532898, -2.2428207397460938, 2.5753173828125, -0.17160016298294067, -2.9521965980529785, -1.6330070495605469, 2.1099538803100586, -1.197441577911377, -5.9389567375183105, -2.6153135299682617, 0.42052891850471497, 1.6437393426895142, 2.9179530143737793, -0.4194609820842743, 3.8722822666168213, -2.620629072189331, -4.050898551940918, 0.23621472716331482, 4.196951866149902, 1.8689396381378174, -4.148056983947754, 1.3833528757095337, -1.1813327074050903, -3.5949532985687256, 0.17619968950748444, -6.100691318511963, 0.9562739729881287, -6.370734214782715, -2.812887191772461, 4.238267421722412, 1.5268988609313965, 1.7044708728790283, 3.861461877822876, 1.1225452423095703, -0.726563572883606, -7.335174560546875, 0.6913520097732544, 3.2282004356384277, 3.7998714447021484, 1.5637043714523315, 6.659047603607178, 0.05154642462730408, -7.102629661560059, 2.055790662765503, 2.293400287628174, -1.1245875358581543, 0.02830839343369007, -4.715290069580078, 5.426046848297119, -1.314296007156372, 5.225160598754883, -4.54453706741333, 2.242194652557373, 6.945626258850098, -1.5153307914733887, 0.21050018072128296, -9.584681510925293, -4.416269302368164, -3.2621638774871826, 3.3322362899780273, -2.8595969676971436, -2.5512022972106934, 3.8596444129943848, 0.4933571219444275, -9.432775497436523, 0.8097963333129883, 1.5538244247436523, 3.059903144836426, -6.216033935546875, 7.149569511413574, 0.7457795143127441, -1.8153877258300781, -0.3011988699436188, -3.6767771244049072, 1.9085699319839478, 0.7994999289512634, 0.9157527089118958, -2.2456679344177246, 4.830585956573486, -1.3583447933197021, 4.74718713760376, -5.104814052581787, -7.081343173980713, -6.917294502258301, 0.4325663447380066, 7.497608661651611, 0.25201040506362915, 8.465133666992188, 4.184858322143555, 3.067284345626831, 1.6993800401687622, -5.735274314880371, -1.328157663345337, -6.9389729499816895]\n",
      "[ 0.092086  0.2571   -0.58693  -0.37029   1.0828   -0.55466  -0.78142\n",
      "  0.58696  -0.58714   0.46318  -0.11267   0.2606   -0.26928  -0.072466\n",
      "  1.247     0.30571   0.56731   0.30509  -0.050312 -0.64443  -0.54513\n",
      "  0.86429   0.20914   0.56334   1.1228   -1.0516   -0.78105   0.29656\n",
      "  0.7261   -0.61392   2.4225    1.0142   -0.17753   0.4147   -0.12966\n",
      " -0.47064   0.3807    0.16309  -0.323    -0.77899  -0.42473  -0.30826\n",
      " -0.42242   0.055069  0.38267   0.037415 -0.4302   -0.39442   0.10511\n",
      "  0.87286 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# to get GloVe vectors: wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "def load_glove_embeddings (path):\n",
    "  embeddings = {}\n",
    "  with open(path , 'r', encoding ='utf−8') as f:\n",
    "    for line in f:\n",
    "      values = line.strip ().split ()\n",
    "      w = values[0]\n",
    "      vectors = np.asarray(values[1:], dtype='float32')\n",
    "      embeddings [w] = vectors\n",
    "  return embeddings\n",
    "\n",
    "# online query\n",
    "import requests\n",
    "import json\n",
    "\n",
    "word = 'happy'\n",
    "response = requests.get('https://icoservices.k8s.tic.heia-fr.ch/word-embedding/wordvector/word2vec/en/' + word)\n",
    "vector = response.json ()\n",
    "print(vector)\n",
    "\n",
    "# off−line dictionary\n",
    "word_dict = load_glove_embeddings ('./glove.6B.50d.txt')\n",
    "word = 'happy'\n",
    "vector = word_dict [word] # if word is in word_dict\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-sixth",
   "metadata": {},
   "source": [
    "c) Prepare the training and testing sets. Prepare the tensors X_train for training\n",
    "by taking the corresponding vectors of 1500 positive and 1500 negative words from the\n",
    "lexicon. Prepare the Y_train target output tensor corresponding to the training set. You\n",
    "can, for example use the target [1.0, 0.0] for a positive word and [0.0, 1.0] for a negative\n",
    "word. For an embedding dimension of 50, the shapes of your X_train and Y_train tensors\n",
    "should be (3000,50) and (3000,2). In a similar way, prepare X_test and Y_test tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "blessed-jumping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4345\n",
      "1893\n",
      "\n",
      "Training dataset: 3000 items\n",
      "[('weariness', [0.0, 1.0]), ('absentee', [0.0, 1.0]), ('suicide', [0.0, 1.0]), ('obnoxiously', [0.0, 1.0]), ('lag', [0.0, 1.0]), ('dissenter', [0.0, 1.0]), ('brood', [0.0, 1.0]), ('unsupportive', [0.0, 1.0]), ('deadweight', [0.0, 1.0]), ('fuck', [0.0, 1.0])]\n",
      "\n",
      "Test dataset: 3238 items\n",
      "[('seething', [0.0, 1.0]), ('disagreeing', [0.0, 1.0]), ('disturbingly', [0.0, 1.0]), ('lawlessness', [0.0, 1.0]), ('jeers', [0.0, 1.0]), ('reluctance', [0.0, 1.0]), ('tanked', [0.0, 1.0]), ('admonishment', [0.0, 1.0]), ('dehumanize', [0.0, 1.0]), ('extravagance', [0.0, 1.0])]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Negative [0.0, 1.0]\n",
    "dataset_neg = [(l, [0.0, 1.0]) for l in vocab_neg if l in word_dict]\n",
    "print(len(dataset_neg))\n",
    "\n",
    "# Positive [1.0, 0.0]\n",
    "dataset_pos = [(l, [1.0, 0.0]) for l in vocab_pos if l in word_dict]\n",
    "print(len(dataset_pos))\n",
    "\n",
    "# Shuffle dataset\n",
    "random.shuffle(dataset_neg)\n",
    "random.shuffle(dataset_pos)\n",
    "\n",
    "# 1500 each for training\n",
    "train_dataset = dataset_neg[:1500] + dataset_pos[:1500]\n",
    "test_dataset = dataset_neg[1500:] + dataset_pos[1500:]\n",
    "\n",
    "print()\n",
    "print(\"Training dataset: {} items\".format(len(train_dataset)))\n",
    "print(train_dataset[:10])\n",
    "print()\n",
    "print(\"Test dataset: {} items\".format(len(test_dataset)))\n",
    "print(test_dataset[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "regulation-istanbul",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 50)\n",
      "[[-0.43838   0.451    -0.073451 ...  0.24796  -0.33154  -0.68768 ]\n",
      " [-0.20688  -1.1166    1.1807   ...  0.65013   0.41145  -0.74624 ]\n",
      " [ 1.1757   -0.32014   0.60612  ...  0.093088  0.89971  -0.079391]\n",
      " ...\n",
      " [ 0.39243   0.29377  -0.2417   ...  1.1159    0.53124   0.22824 ]\n",
      " [-0.25846   0.69529   1.2285   ...  0.576    -0.31104   0.37334 ]\n",
      " [-0.23231   0.87132  -0.076435 ... -0.15028  -0.61933  -0.16051 ]]\n",
      "(3000, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray([word_dict[x[0]] for x in train_dataset])\n",
    "Y_train = np.asarray([x[1] for x in train_dataset])\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(X_train)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "synthetic-scene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3238, 50)\n",
      "(3238, 2)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.asarray([word_dict[x[0]] for x in test_dataset])\n",
    "Y_test = np.asarray([x[1] for x in test_dataset])\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-temple",
   "metadata": {},
   "source": [
    "d) Train and evaluate a classifier. Build a model, e.g. a double Dense layers in Keras\n",
    "(MLP) and train it. Report on the evolution of the loss and accuracy along the epochs.\n",
    "You should reach about 90% accuracy on the training set and 85% accuracy on the test\n",
    "set. Report on your model structure and fitting strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "alert-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "copyrighted-snowboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 128)               6528      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 6,786\n",
      "Trainable params: 6,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define our model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, input_shape=X_train[0].shape))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "powered-knowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6119 - accuracy: 0.6628\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 796us/step - loss: 0.3593 - accuracy: 0.8446\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 707us/step - loss: 0.3163 - accuracy: 0.8696\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 672us/step - loss: 0.3234 - accuracy: 0.8626\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 697us/step - loss: 0.3140 - accuracy: 0.8698\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 689us/step - loss: 0.3347 - accuracy: 0.8467\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 711us/step - loss: 0.3417 - accuracy: 0.8641\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 710us/step - loss: 0.3228 - accuracy: 0.8623\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 710us/step - loss: 0.3050 - accuracy: 0.8790\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 830us/step - loss: 0.3157 - accuracy: 0.8692\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 757us/step - loss: 0.3255 - accuracy: 0.8580\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 721us/step - loss: 0.2939 - accuracy: 0.8771\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 719us/step - loss: 0.3349 - accuracy: 0.8591\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 0s 740us/step - loss: 0.3001 - accuracy: 0.8739\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 0s 721us/step - loss: 0.3192 - accuracy: 0.8615\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 0s 724us/step - loss: 0.3118 - accuracy: 0.8688\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 0s 703us/step - loss: 0.3076 - accuracy: 0.8703\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 0s 716us/step - loss: 0.3208 - accuracy: 0.8641\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 0s 662us/step - loss: 0.3369 - accuracy: 0.8529\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 0s 720us/step - loss: 0.3233 - accuracy: 0.8653\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 0s 680us/step - loss: 0.3191 - accuracy: 0.8626\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 0s 734us/step - loss: 0.3155 - accuracy: 0.8643\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 0s 739us/step - loss: 0.3183 - accuracy: 0.8627\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 0s 714us/step - loss: 0.3105 - accuracy: 0.8677\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 0s 692us/step - loss: 0.3225 - accuracy: 0.8610\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 0s 712us/step - loss: 0.3049 - accuracy: 0.8751\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 0s 683us/step - loss: 0.2946 - accuracy: 0.8791\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 0s 668us/step - loss: 0.3235 - accuracy: 0.8569\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 0s 697us/step - loss: 0.3070 - accuracy: 0.8704\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 0s 715us/step - loss: 0.3162 - accuracy: 0.8661\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 0s 709us/step - loss: 0.3259 - accuracy: 0.8617\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 0s 707us/step - loss: 0.3044 - accuracy: 0.8711\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 0s 704us/step - loss: 0.3152 - accuracy: 0.8637\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 0s 895us/step - loss: 0.3179 - accuracy: 0.8662\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 0s 796us/step - loss: 0.3169 - accuracy: 0.8678\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 0s 710us/step - loss: 0.3165 - accuracy: 0.8604\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 0s 708us/step - loss: 0.3321 - accuracy: 0.8604\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 0s 696us/step - loss: 0.3314 - accuracy: 0.8600\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 0s 705us/step - loss: 0.3111 - accuracy: 0.8623\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 0s 764us/step - loss: 0.3197 - accuracy: 0.8655\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 0s 731us/step - loss: 0.3132 - accuracy: 0.8652\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 0s 696us/step - loss: 0.3198 - accuracy: 0.8680\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 0s 696us/step - loss: 0.3145 - accuracy: 0.8645\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 0s 687us/step - loss: 0.3013 - accuracy: 0.8728\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 0s 713us/step - loss: 0.3125 - accuracy: 0.8706\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 0s 709us/step - loss: 0.2976 - accuracy: 0.8734\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 0s 730us/step - loss: 0.3177 - accuracy: 0.8611\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 0s 725us/step - loss: 0.3052 - accuracy: 0.8743\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 0s 715us/step - loss: 0.3189 - accuracy: 0.8587\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 0s 717us/step - loss: 0.3087 - accuracy: 0.8702\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 0s 692us/step - loss: 0.3208 - accuracy: 0.8679\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 0s 722us/step - loss: 0.3027 - accuracy: 0.8713\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 0s 734us/step - loss: 0.3065 - accuracy: 0.8675\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 0s 739us/step - loss: 0.3085 - accuracy: 0.8723\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 0s 755us/step - loss: 0.3155 - accuracy: 0.8631\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 0s 723us/step - loss: 0.3075 - accuracy: 0.8642\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 0s 759us/step - loss: 0.3023 - accuracy: 0.8679\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 0s 702us/step - loss: 0.3104 - accuracy: 0.8629\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 0s 729us/step - loss: 0.3115 - accuracy: 0.8676\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 0s 738us/step - loss: 0.3235 - accuracy: 0.8623\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 0s 745us/step - loss: 0.3026 - accuracy: 0.8678\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 0s 769us/step - loss: 0.3023 - accuracy: 0.8703\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 0s 721us/step - loss: 0.3147 - accuracy: 0.8729\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 0s 753us/step - loss: 0.3204 - accuracy: 0.8579\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 0s 779us/step - loss: 0.3034 - accuracy: 0.8697\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 0s 710us/step - loss: 0.3045 - accuracy: 0.8707\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 0s 751us/step - loss: 0.3046 - accuracy: 0.8792\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 0s 712us/step - loss: 0.3074 - accuracy: 0.8647\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 0s 732us/step - loss: 0.3124 - accuracy: 0.8615\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 0s 715us/step - loss: 0.3160 - accuracy: 0.8681\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 0s 754us/step - loss: 0.3040 - accuracy: 0.8651\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 0s 765us/step - loss: 0.3166 - accuracy: 0.8647\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 0s 712us/step - loss: 0.3128 - accuracy: 0.8615\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 0s 747us/step - loss: 0.3133 - accuracy: 0.8690\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 0s 742us/step - loss: 0.3112 - accuracy: 0.8710\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 0s 748us/step - loss: 0.3189 - accuracy: 0.8609\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 0s 745us/step - loss: 0.3146 - accuracy: 0.8671\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 0s 750us/step - loss: 0.3050 - accuracy: 0.8724\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 0s 752us/step - loss: 0.3204 - accuracy: 0.8610\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 0s 700us/step - loss: 0.3322 - accuracy: 0.8558\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 779us/step - loss: 0.2957 - accuracy: 0.8748\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 0s 813us/step - loss: 0.3124 - accuracy: 0.8692\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 0s 780us/step - loss: 0.2995 - accuracy: 0.8821\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 0s 769us/step - loss: 0.3258 - accuracy: 0.8582\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 0s 761us/step - loss: 0.3227 - accuracy: 0.8606\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 0s 758us/step - loss: 0.3077 - accuracy: 0.8666\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 0s 763us/step - loss: 0.2970 - accuracy: 0.8737\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 0s 706us/step - loss: 0.3312 - accuracy: 0.8590\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 0s 697us/step - loss: 0.3202 - accuracy: 0.8681\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 0s 717us/step - loss: 0.3051 - accuracy: 0.8734\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 0s 720us/step - loss: 0.3010 - accuracy: 0.8674\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 0s 739us/step - loss: 0.3080 - accuracy: 0.8701\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 0s 715us/step - loss: 0.3118 - accuracy: 0.8684\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 0s 710us/step - loss: 0.3056 - accuracy: 0.8660\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 0s 655us/step - loss: 0.3199 - accuracy: 0.8668\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 0s 733us/step - loss: 0.2954 - accuracy: 0.8767\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 0s 747us/step - loss: 0.2993 - accuracy: 0.8713\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - 0s 674us/step - loss: 0.3039 - accuracy: 0.8735\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - 0s 759us/step - loss: 0.3035 - accuracy: 0.8707\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - 0s 777us/step - loss: 0.3216 - accuracy: 0.8616\n"
     ]
    }
   ],
   "source": [
    "log = model.fit(X_train, Y_train, epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "foster-trust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(log.history['accuracy'], label='Training')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "illegal-costume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.751080\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-laugh",
   "metadata": {},
   "source": [
    "e) Analysis of results and discussions. Report on your experiments and comment your\n",
    "classification performances. Find 5 to 10 words which are not in your training set and on\n",
    "which the system thinks it is clearly positive or negative. Find some words on which the\n",
    "system hesitates, i.e. with output probabilities in range [0.4-0.6]). Are these words and\n",
    "outputs making sense to you ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "amended-thesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00412393 0.99587613]\n",
      " [0.13236877 0.86763126]\n",
      " [0.09507057 0.9049294 ]\n",
      " ...\n",
      " [0.8593548  0.14064519]\n",
      " [0.9422926  0.05770747]\n",
      " [0.8078514  0.1921487 ]]\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "8.554486844447595e-06\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "import pandas as pd\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "print(Y_pred)\n",
    "print(Y_test)\n",
    "\n",
    "dist = spatial.distance.cosine(Y_pred[0], Y_test[0])\n",
    "print(dist)\n",
    "\n",
    "columns_name = [\"word\", \"label\", \"pred\", \"dist\"]\n",
    "df_pred = pd.DataFrame(columns = columns_name)\n",
    "\n",
    "for i in range(len(Y_test)):\n",
    "    if Y_test[i][0]== 0:\n",
    "        lbl = \"neg\"\n",
    "    else:\n",
    "        lbl = \"pos\"\n",
    "    df_pred = df_pred.append({'word': test_dataset[i][0],         \n",
    "                    'label': lbl,\n",
    "                    'pred': Y_pred[i],\n",
    "                    'dist': spatial.distance.cosine(Y_pred[i], Y_test[i])\n",
    "                             },\n",
    "                             ignore_index = True\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "collected-forge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            word label                         pred          dist\n",
      "2053     rampant   neg   [0.00015515032, 0.9998448]  1.204889e-08\n",
      "489         rash   neg   [0.00015562224, 0.9998443]  1.212305e-08\n",
      "564   starvation   neg   [0.0002941242, 0.99970585]  1.635247e-08\n",
      "711        leaks   neg    [0.00026403638, 0.999736]  2.477263e-08\n",
      "1296     scandal   neg  [0.00024574407, 0.99975425]  2.942258e-08\n"
     ]
    }
   ],
   "source": [
    "# Top negative words\n",
    "df_top_neg = df_pred[df_pred['label']=='neg'].sort_values(by=['dist'], ascending=True)\n",
    "print(df_top_neg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "departmental-surveillance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            word label                        pred          dist\n",
      "3139       award   pos  [0.9999893, 1.0706776e-05]  5.755529e-11\n",
      "3122  excellence   pos   [0.9999888, 1.116191e-05]  6.278489e-11\n",
      "2907       prize   pos   [0.9999236, 7.642538e-05]  2.919931e-09\n",
      "3028  innovative   pos  [0.9998759, 0.00012406897]  7.701928e-09\n",
      "2894  all-around   pos  [0.9997049, 0.00029506258]  1.607136e-08\n"
     ]
    }
   ],
   "source": [
    "# Top positive words\n",
    "df_top_pos = df_pred[df_pred['label']=='pos'].sort_values(by=['dist'], ascending=True)\n",
    "print(df_top_pos.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "contained-subscriber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              word label                       pred      dist\n",
      "237       grudging   neg   [0.998676, 0.0013239147]  0.998674\n",
      "1324          vice   neg  [0.99258596, 0.007413982]  0.992531\n",
      "3126         eases   pos  [0.008551548, 0.99144846]  0.991375\n",
      "780   incomparable   neg   [0.9913413, 0.008658766]  0.991266\n",
      "1614  incomparably   neg  [0.9892244, 0.0107755875]  0.989108\n"
     ]
    }
   ],
   "source": [
    "# The most mistaken words\n",
    "df_top_wrong = df_pred.sort_values(by=['dist'], ascending=False)\n",
    "print(df_top_wrong.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "rising-school",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              word label                      pred      dist\n",
      "48      freakishly   neg  [0.60037655, 0.39962336]  0.445902\n",
      "55          scarce   neg   [0.6565204, 0.34347966]  0.536429\n",
      "86          madden   neg    [0.6914891, 0.3085109]  0.592558\n",
      "117   unsettlingly   neg  [0.62143356, 0.37856644]  0.479750\n",
      "119       inferior   neg    [0.6624995, 0.3375005]  0.546073\n",
      "...            ...   ...                       ...       ...\n",
      "3067   subsidizing   pos  [0.31554046, 0.68445945]  0.581340\n",
      "3088       staunch   pos  [0.42361578, 0.57638425]  0.407788\n",
      "3149       idolize   pos   [0.4160997, 0.58390033]  0.419660\n",
      "3209      famously   pos  [0.39122415, 0.60877585]  0.459371\n",
      "3218      morality   pos   [0.3078024, 0.69219756]  0.593686\n",
      "\n",
      "[119 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Words with hesitation\n",
    "df_hes = df_pred[(df_pred['dist']>0.4) & (df_pred['dist']<0.6)]\n",
    "print(df_hes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-tourist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
